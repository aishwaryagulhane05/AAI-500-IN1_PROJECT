{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e747284-fc94-4001-b32b-3903f9d11d1d",
   "metadata": {},
   "source": [
    "## NOTE: Import module and use module prefix\n",
    "### To import module src directly mention file and use as prefix\n",
    "import data_utils\n",
    "data_utils.function_name();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d885f31-752d-49e2-b663-320670f55c26",
   "metadata": {},
   "source": [
    "## Phase 2: Exploratory Data Analysis (EDA)\n",
    "\n",
    "Hereâ€™s a detailed breakdown of **Exploratory Data Analysis (EDA)** steps categorized into **Beginner**, **Moderate**, and **Advanced** levels. This categorization helps you progress systematically as you gain more experience.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ”° **Beginner Level: Foundation Building**\n",
    "\n",
    "Basic steps to understand the data and ensure it's usable.\n",
    "\n",
    "### 1. **Understand the Dataset**\n",
    "\n",
    "* Load data (`.csv`, `.xlsx`, etc.)\n",
    "* Check shape, columns, data types (`df.shape`, `df.info()`)\n",
    "* Preview data (`df.head()`, `df.tail()`)\n",
    "\n",
    "### 2. **Handle Missing Values**\n",
    "\n",
    "* Detect nulls (`df.isnull().sum()`)\n",
    "* Basic handling: drop rows/columns, fill with mean/median/mode\n",
    "\n",
    "### 3. **Descriptive Statistics**\n",
    "\n",
    "* Use `.describe()` for numerical summaries\n",
    "* Count unique values for categorical columns\n",
    "* Frequency distribution using `value_counts()`\n",
    "\n",
    "### 4. **Basic Data Cleaning**\n",
    "\n",
    "* Strip spaces, convert to proper formats (`datetime`, `numeric`)\n",
    "* Handle duplicates (`df.duplicated()`)\n",
    "* Rename columns for clarity\n",
    "\n",
    "### 5. **Basic Visualizations**\n",
    "\n",
    "* Histograms (distribution)\n",
    "* Bar plots (categorical)\n",
    "* Box plots (spread and outliers)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸš€ **Moderate Level: Pattern Discovery**\n",
    "\n",
    "Begin asking analytical questions and looking for insights.\n",
    "\n",
    "### 1. **Data Type and Format Refinement**\n",
    "\n",
    "* Convert data types explicitly (`pd.to_datetime`, `astype()`)\n",
    "* Create calculated fields (e.g., profit = sales - cost)\n",
    "\n",
    "### 2. **Outlier Detection**\n",
    "\n",
    "* Visual: boxplots, scatter plots\n",
    "* Statistical: IQR method, Z-score\n",
    "\n",
    "### 3. **Univariate & Bivariate Analysis**\n",
    "\n",
    "* Distribution of single variables\n",
    "* Relationships between two variables:\n",
    "\n",
    "  * Numerical vs Numerical: scatter plot, correlation heatmap\n",
    "  * Categorical vs Numerical: groupby + aggregation\n",
    "  * Categorical vs Categorical: crosstab, stacked bar plot\n",
    "\n",
    "### 4. **Feature Engineering (Basic)**\n",
    "\n",
    "* Derive new columns (e.g., `total_spent = quantity * price`)\n",
    "* Extract features from datetime (month, day, hour)\n",
    "\n",
    "### 5. **Handling Imbalanced Data (if applicable)**\n",
    "\n",
    "* Detect class imbalance\n",
    "* Consider techniques like stratified sampling (for modeling)\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  **Advanced Level: Deep Insights & Preparation for Modeling**\n",
    "\n",
    "### 1. **Multivariate Analysis**\n",
    "\n",
    "* Pair plots\n",
    "* Correlation matrix\n",
    "* PCA for dimensionality reduction (for visualization)\n",
    "\n",
    "### 2. **Advanced Outlier Treatment**\n",
    "\n",
    "* Winsorization\n",
    "* Robust scaling\n",
    "* Isolation Forest (optional)\n",
    "\n",
    "### 3. **Feature Engineering (Advanced)**\n",
    "\n",
    "* Encoding: one-hot, label, target\n",
    "* Transformation: log, sqrt, power transformations\n",
    "* Interaction terms between variables\n",
    "* Normalization/Standardization\n",
    "\n",
    "### 4. **Time Series Decomposition (for time data)**\n",
    "\n",
    "* Trend, seasonality, residual\n",
    "* Rolling statistics\n",
    "* Lag features\n",
    "\n",
    "### 5. **EDA for Text Data**\n",
    "\n",
    "* Tokenization, stopword removal\n",
    "* Word frequency analysis\n",
    "* WordCloud, n-gram analysis\n",
    "\n",
    "### 6. **EDA for Date/Time Patterns**\n",
    "\n",
    "* Time-based aggregation (monthly, weekly trends)\n",
    "* Festival/seasonal patterns\n",
    "* Time to event analysis\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Summary Table\n",
    "\n",
    "| Level    | Key Focus Areas                                                |\n",
    "| -------- | -------------------------------------------------------------- |\n",
    "| Beginner | Data loading, cleaning, missing values, basic visualizations   |\n",
    "| Moderate | Outliers, feature engineering, bivariate plots, group analysis |\n",
    "| Advanced | Multivariate EDA, text/time series, scaling, encodings         |\n",
    "\n",
    "---\n",
    "\n",
    "Would you like this in a printable PDF format with code examples or added to your current EDA project structure?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c4a917c-db11-4426-a41f-40f25151242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fd40827-d397-451f-893c-1727fcb5eed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/Isha/anaconda3/envs/usd_env/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "# /home/Isha/anaconda3/envs/usd_env/bin/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bc6d1af-354d-4cd0-8474-ab2b3746e833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('../src'))  # adjust relative path if needed\n",
    "import data_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf9bdd9d-b5d2-4576-a7e4-3ef588ab685f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values containing special characters:\n",
      "['XYZ@456', '789_ABC', 'DEF456!']\n"
     ]
    }
   ],
   "source": [
    "import src.data_utils\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\n",
    "    'ProductNo': ['ABC123', 'XYZ@456', '789_ABC', 'DEF456!', 'GHI789']\n",
    "})\n",
    "\n",
    "\n",
    "\n",
    "result = get_values_with_special_chars(df, 'ProductNo')\n",
    "\n",
    "print(\"Values containing special characters:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d653a7-907f-4c96-ac3e-d2e7f80fd26d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
